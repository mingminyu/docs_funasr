{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"FunASR","text":"<p>FunASR \u662f\u963f\u91cc\u8fbe\u6469\u9662\u5f00\u6e90\u7684\u57fa\u7840\u8bed\u97f3\u8bc6\u522b\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u975e\u5e38\u4e30\u5bcc\u7684\u529f\u80fd\uff0c\u5305\u62ec \u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u3001\u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b\uff08VAD\uff09\u3001\u6807\u70b9\u6062\u590d\u3001\u8bed\u8a00\u6a21\u578b\u3001\u8bf4\u8bdd\u4eba\u9a8c\u8bc1 \u3001\u8bf4\u8bdd\u4eba\u5206\u79bb \u548c \u591a\u4eba\u5bf9\u8bdd\u8bed\u97f3\u8bc6\u522b \u7b49\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u811a\u672c\u548c\u6559\u7a0b\uff0c\u652f\u6301\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u7684\u63a8\u7406\u4e0e\u5fae\u8c03\u3002\u5176\u4ee3\u8868\u6027\u7684 Paraformer <sup>1</sup> \u975e\u81ea\u56de\u5f52\u7aef\u5230\u7aef\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u3001\u4fbf\u6377\u90e8\u7f72\u7684\u4f18\u70b9\uff0c\u652f\u6301\u5feb\u901f\u6784\u5efa\u8bed\u97f3\u8bc6\u522b\u670d\u52a1\u3002</p> <p></p> <ol> <li> <p>Paraformer: https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary \u21a9</p> </li> </ol>"},{"location":"asr/","title":"\u8bed\u97f3\u8bc6\u522b","text":"<p>\u8bed\u97f3\u8bc6\u522b\u662f FunASR \u4e2d\u975e\u5e38\u6838\u5fc3\u7684\u529f\u80fd\uff0c\u5b83\u63d0\u4f9b\u4e86\u5b9e\u65f6\u4ee5\u53ca\u975e\u5b9e\u65f6\u7684\u591a\u79cd\u6a21\u578b\uff08\u8be6\u89c1\u6a21\u578b\u4ed3\u5e93\uff09\uff0c\u5e76\u4e14\u53ef\u4ee5\u7ed3\u5408\u6807\u70b9\u6062\u590d\u3001\u60c5\u611f\u8bc6\u522b\u7b49\u6a21\u578b\u4e00\u8d77\u4f7f\u7528\u3002</p> <p>\u5728 Python \u4e2d\u8c03\u7528 FunASR \u8fdb\u884c\u8bed\u97f3\u8bc6\u522b\u975e\u5e38\u7b80\u6d01\u4e14\u9ad8\u6548\uff0c\u53ea\u9700\u8981\u7b80\u5355\u51e0\u884c\u4ee3\u7801\u5c31\u53ef\u4ee5\u5b8c\u6210\u76f8\u5e94\u7684\u529f\u80fd\uff0c\u4f60\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684\u6a21\u578b\uff08\u5982 SenseVoice\u3001Paraformer \u4ee5\u53ca\u4e00\u4e9b\u6d41\u5f0f\u6a21\u578b\uff09\u6765\u9a8c\u8bc1\u4e0d\u540c\u7684\u8bc6\u522b\u6548\u679c\u3002</p>"},{"location":"asr/#1-asr","title":"1. \u975e\u5b9e\u65f6 ASR","text":""},{"location":"asr/#11-paraformer","title":"1.1 Paraformer","text":"<pre><code>from funasr import AutoModel\n\nwav_file = \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav\"\nmodel = AutoModel(model=\"paraformer-zh\")\nres = model.generate(input=wav_file)\nprint(res)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c\u4e3a\u4e00\u4e2a\u5217\u8868\uff0c\u5305\u542b\u6587\u4ef6\u540d\u3001\u8f6c\u5199\u6587\u672c\u4ee5\u53ca\u65f6\u95f4\u6233\u4fe1\u606f\u3002</p> \u8f93\u51fa\u7ed3\u679c<pre><code>[\n  {\n    'key': 'vad_example', \n    'text': '\u8bd5 \u9519 \u7684 \u8fc7 \u7a0b \u5f88 \u7b80 \u5355 \u800c \u4e14 ...',\n    'timestamp': [[390, 630], [650, 770], [770, 970], ...]  # (1)!\n  }\n]\n</code></pre> <ol> <li>\u6bcf\u4e2a\u8f6c\u5199\u5b57\u7b26\u5bf9\u5e94\u65f6\u95f4\u6233\u3002</li> </ol> <p>\u6b64\u5916\uff0cParaformer-zh \u662f\u4e00\u4e2a\u591a\u529f\u80fd\u7684 ASR \u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 <code>AutoModel</code> \u4e2d\u6307\u5b9a\u7aef\u70b9\u68c0\u6d4b\u3001\u6807\u70b9\u6062\u590d\u3001\u8bf4\u8bdd\u4eba\u8bc6\u522b\u7b49\u6a21\u578b\u3002</p> <pre><code>from funasr import AutoModel\n\nwav_file = \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav\"\nmodel = AutoModel(\n  model=\"paraformer-zh\", \n  vad_model=\"fsmn-vad\",\n  vad_kwargs={\"max_single_segment_time\": 60000},\n  punc_model=\"ct-punc\", \n  # spk_model=\"cam++\"\n  )\nres = model.generate(\n  input=wav_file, \n  batch_size_s=300,\n  batch_size_threshold_s=60,\n  hotword='\u9b54\u642d'\n  )\nprint(res)\n</code></pre>"},{"location":"asr/#12-sensevoice","title":"1.2 SenseVoice","text":"<p>SenseVoice \u63d0\u4f9b\u4e86\u591a\u79cd\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u6db5\u76d6\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u3001\u8bed\u8a00\u8bc6\u522b\uff08LID\uff09\u3001\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\u4ee5\u53ca\u97f3\u9891\u4e8b\u4ef6\u68c0\u6d4b\uff08AED\uff09\u3002</p> <pre><code>from funasr import AutoModel\nfrom funasr.utils.postprocess_utils import rich_transcription_postprocess\n\nmodel_dir = \"iic/SenseVoiceSmall\"\n\nmodel = AutoModel(\n    model=model_dir,\n    vad_model=\"fsmn-vad\",\n    vad_kwargs={\"max_single_segment_time\": 30000},\n    device=\"cuda:0\",\n)\n\nres = model.generate(\n    input=f\"{model.model_path}/example/en.mp3\",\n    cache={},\n    language=\"auto\",  # (1)!\n    use_itn=True,  # \u8f93\u51fa\u7ed3\u679c\u4e2d\u662f\u5426\u5305\u542b\u6807\u70b9\u4e0e\u9006\u6587\u672c\u6b63\u5219\u5316\n    batch_size_s=60,\n    merge_vad=True,\n    merge_length_s=15,\n)\ntext = rich_transcription_postprocess(res[0][\"text\"])\nprint(text)\n</code></pre> <ol> <li>\u652f\u6301 <code>zn</code>, <code>en</code>, <code>yue</code>, <code>ja</code>, <code>ko</code>, <code>nospeech</code>\u3002</li> </ol>"},{"location":"asr/#2-asr","title":"2. \u5b9e\u65f6 ASR","text":""},{"location":"asr/#21-asr","title":"2.1 \u8bfb\u53d6\u97f3\u9891\u6587\u4ef6\u6a21\u62df\u5b9e\u65f6 ASR","text":"<p>Paraformer-zh-streaming \u662f\u4e00\u4e2a\u5b9e\u65f6\u7684\u8bed\u97f3\u8bc6\u522b\u5f15\u64ce\uff0c\u4ee5\u4e0b\u793a\u4f8b\u662f\u8bfb\u53d6\u4e00\u4e2a\u97f3\u9891\u6587\u4ef6\uff0c\u7136\u540e\u904d\u5386\u5b57\u8282\u6d41\u6765\u6a21\u62df\u5b9e\u65f6\u8bc6\u522b\u7684\u573a\u666f\u3002</p> <pre><code>import os\nimport soundfile\nfrom funasr import AutoModel\n\n#[0, 10, 5] =&gt; 600ms, [0, 8, 4] =&gt; 480ms\nchunk_size = [0, 10, 5]  # (1)!\nencoder_chunk_look_back = 4  # \u81ea\u6ce8\u610f\u529b\u7f16\u7801\u5668\u56de\u6eaf\u7684 chunk \u6570\u91cf\ndecoder_chunk_look_back = 1  # \u4ea4\u53c9\u6ce8\u610f\u529b\u7f16\u7801\u5668\u56de\u6eaf\u7684 chunk \u6570\u91cf \nmodel = AutoModel(model=\"paraformer-zh-streaming\")\n\nwav_file = os.path.join(model.model_path, \"example/asr_example.wav\")\nspeech, sample_rate = soundfile.read(wav_file)\nchunk_stride = chunk_size[1] * 960  # 600ms\n\ncache = {}\ntotal_chunk_num = int(len(speech - 1) / chunk_stride + 1)\n\nfor i in range(total_chunk_num):\n    speech_chunk = speech[i * chunk_stride: (i + 1) * chunk_stride]\n    is_final = i == total_chunk_num - 1\n    res = model.generate(\n      input=speech_chunk, \n      cache=cache, \n      is_final=is_final,\n      chunk_size=chunk_size, \n      encoder_chunk_look_back=encoder_chunk_look_back,\n      decoder_chunk_look_back=decoder_chunk_look_back\n      )\n    print(res)\n</code></pre> <ol> <li><code>chunk_size</code> \u4e3a\u6d41\u5f0f\u5ef6\u65f6\u914d\u7f6e\uff0c<code>[0,10,5]</code> \u8868\u793a\u4e0a\u5c4f\u5b9e\u65f6\u51fa\u5b57\u7c92\u5ea6\u4e3a 10x60=600ms\uff0c\u672a\u6765\u4fe1\u606f\u4e3a 5x60=300ms\u3002\u6bcf\u6b21\u63a8\u7406\u8f93\u5165\u4e3a 600ms\uff08\u91c7\u6837\u70b9\u6570\u4e3a 16000x0.6=960\uff09\uff0c\u8f93\u51fa\u4e3a\u5bf9\u5e94\u6587\u5b57\uff0c\u6700\u540e\u4e00\u4e2a\u8bed\u97f3\u7247\u6bb5\u8f93\u5165\u9700\u8981\u8bbe\u7f6e <code>is_final=True</code> \u6765\u5f3a\u5236\u8f93\u51fa\u6700\u540e\u4e00\u4e2a\u5b57\u3002</li> </ol>"},{"location":"asr/#22-asr","title":"2.2 \u4f7f\u7528\u9ea6\u514b\u98ce\u8fdb\u884c\u5b9e\u65f6 ASR","text":"<p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4f7f\u7528\u901a\u8fc7\u5f00\u542f\u9ea6\u514b\u98ce\uff0c\u8fdb\u884c\u5b9e\u65f6\u8bed\u97f3\u8bc6\u522b\u3002</p> <pre><code>import sys\nimport sounddevice as sd\nimport numpy as np\nimport queue\nimport threading\nimport time\nfrom funasr import AutoModel\n\n\nsample_rate = 16000  # \u91c7\u6837\u7387\ndevice = 0  # \u8f93\u5165\u8bbe\u5907ID\uff0c\u53ef\u4ee5\u7528 `sd.query_devices()` \u67e5\u770b\nchunk_size = [0, 10, 5]  \nencoder_chunk_look_back = 4  # \u81ea\u6ce8\u610f\u529b\u7f16\u7801\u5668\u56de\u6eaf\u7684 chunk \u6570\u91cf\ndecoder_chunk_look_back = 1  # \u4ea4\u53c9\u6ce8\u610f\u529b\u7f16\u7801\u5668\u56de\u6eaf\u7684 chunk \u6570\u91cf \nchunk_stride = chunk_size[1] * 960\n\n# \u521d\u59cb\u5316 FunASR \u6a21\u578b\nasr_model = AutoModel(model=\"paraformer-zh-streaming\")\n\n# \u521b\u5efa\u97f3\u9891\u961f\u5217\naudio_queue = queue.Queue()\ncache = {}\ntexts = []\n\ndef audio_callback(indata, frames, time, status):\n    if status:\n        print(status, file=sys.stderr)\n    # \u5c06\u97f3\u9891\u6570\u636e\u653e\u5165\u961f\u5217\u4e2d\n    audio_queue.put(indata.copy())\n\ndef recognize_audio():\n    print(\"\u5f00\u59cb\u5b9e\u65f6\u8bed\u97f3\u8bc6\u522b...\")\n    while True:\n        # \u4ece\u961f\u5217\u4e2d\u83b7\u53d6\u97f3\u9891\u5757\n        if not audio_queue.empty():\n            audio_data = audio_queue.get()\n            # \u5c06\u97f3\u9891\u6570\u636e\u8f6c\u6362\u4e3a\u9002\u5408\u6a21\u578b\u8f93\u5165\u7684\u683c\u5f0f\n            audio_data = audio_data.flatten()\n            # \u8c03\u7528\u6a21\u578b\u8fdb\u884c\u8bc6\u522b\n            # result = asr_model(audio_data)\n            res = asr_model.generate(\n                input=audio_data, \n                cache=cache, \n                is_final=False,\n                chunk_size=chunk_size, \n                encoder_chunk_look_back=encoder_chunk_look_back,\n                decoder_chunk_look_back=decoder_chunk_look_back\n                )\n\n            texts.append(res[0][\"text\"])\n            print(\"\u8bc6\u522b\u7ed3\u679c:\", res[0][\"text\"])\n\n            if \"\u5173\u673a\" in \"\".join(texts):\n                print(\"\u68c0\u6d4b\u5230\u8bed\u97f3\u64ad\u62a5\uff1a\", \"\u5173\u673a\")\n                sys.exit()\n\n# \u521b\u5efa\u97f3\u9891\u6d41\nwith sd.InputStream(\n    samplerate=sample_rate, blocksize=chunk_stride, \n    device=device, channels=1, callback=audio_callback\n    ):\n    # \u542f\u52a8\u8bc6\u522b\u7ebf\u7a0b\n    recognition_thread = threading.Thread(target=recognize_audio)\n    recognition_thread.start()\n\n    # \u8ba9\u4e3b\u7ebf\u7a0b\u6301\u7eed\u8fd0\u884c\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        print(\"\\n\u505c\u6b62\u5b9e\u65f6\u8bed\u97f3\u8bc6\u522b\u3002\")\n</code></pre>"},{"location":"asr/#3-automodel-api","title":"3. AutoModel API \u4f7f\u7528","text":""},{"location":"asr/#31","title":"3.1 \u5b9a\u4e49","text":"<pre><code>model = AutoModel(\n    model: str,\n    device: str = \"cuda:0\",\n    ncpu: int = 4,\n    output_dir: str = None,\n    batch_size: int = 1\n    hub: str = \"ms\",\n    **kwrags\n)\n</code></pre> \u53c2\u6570 \u8bf4\u660e model \u6a21\u578b\u540d\u79f0 device \u9ed8\u8ba4\u4f7f\u7528 GPU \u63a8\u7406\uff0c\u9700\u8981\u4f7f\u7528 CPU \u7684\u8bdd\u8bf7\u8bbe\u7f6e\u4e3a <code>cpu</code> ncpu \u5904\u7406\u7ebf\u7a0b\u6570\uff0c\u9ed8\u8ba4\u4e3a 4 output_dir \u7ed3\u679c\u7684\u8f93\u51fa\u8def\u5f84 batch_size \u89e3\u7801\u65f6\u7684\u6279\u5904\u7406\u6837\u672c\u4e2a\u6570 hub \u9ed8\u8ba4\u662f\u4ece ModelScope \u4e0a\u4e0b\u8f7d\u6a21\u578b\uff0c\u6307\u5b9a\u4e3a <code>hf</code> \u5219\u4f1a\u4ece HuggingFace \u4e0a\u4e0b\u8f7d\u6a21\u578b vad_model \u7aef\u70b9\u68c0\u6d4b\u6a21\u578b\uff0c\u901a\u5e38\u6a21\u578b\u9650\u5236\u8f93\u5165\u65f6\u957f\u4e3a 30s\uff0c\u4f7f\u7528 VAD \u540e\u53ef\u4efb\u610f\u6269\u5c55 vad_kwargs VAD \u6a21\u578b\u7684\u53c2\u6570\uff0c\u4f8b\u5982 <code>max_single_segment_time=6000</code> \u7528\u4e8e\u8bbe\u7f6e\u6700\u5927\u5207\u5272\u957f\u5ea6\u4e3a 6s\u3002 punc_kwargs \u6807\u70b9\u6062\u590d\u6a21\u578b spk_kwargs \u8bf4\u8bdd\u4eba\u8bc6\u522b\u6a21\u578b"},{"location":"asr/#32","title":"3.2 \u63a8\u7406","text":"<p>\u4f7f\u7528 <code>AutoModel.generate</code> \u51fd\u6570\u8fdb\u884c\u63a8\u7406\uff1a</p> <pre><code>res = model.generate(\n  input=\"xxx\", \n  output_dir=\"xxx\",\n  batch_size_s=300,\n  batch_size_threshold_s=60,\n  hotword='\u9b54\u642d'\n  )\n</code></pre> \u53c2\u6570 \u8bf4\u660e input \u652f\u6301 wav\u3001pcm\u3001\u97f3\u9891\u5b57\u8282\u6d41\u3001wav.scp \u683c\u5f0f\u7684\u8f93\u5165\uff0c\u4f7f\u7528 wav.scp \u683c\u5f0f\u65f6\uff0c\u5219\u5fc5\u987b\u6307\u5b9a <code>output_dir</code>\u3002 output_dir \u7ed3\u679c\u7684\u8f93\u51fa\u8def\u5f84\uff0c\u5982\u679c\u5728\u5b9a\u4e49\u65f6\u5df2\u7ecf\u8bbe\u5b9a\uff0c\u5219\u4e0d\u9700\u8981\u518d\u8bbe\u7f6e batch_size_s \u542f\u7528\u52a8\u6001 batch\uff0c\u6bcf\u4e2a batch\u4e2d\u603b\u97f3\u9891\u65f6\u957f\uff0c\u5355\u4f4d\u4e3a\u79d2\u3002 batch_size_threshold_s \u662f\u5426\u5c06 vad \u6a21\u578b\u5207\u5272\u7684\u77ed\u97f3\u9891\u788e\u7247\u5408\u6210\uff0c\u5408\u5e76\u540e\u957f\u5ea6\u4e3a<code>merge_length_s</code>\uff0c\u5355\u4f4d\u4e3a\u79d2\u3002 merge_length_s \u5408\u6210\u97f3\u9891\u957f\u5ea6\uff0c\u5355\u4f4d\u4e3a\u79d2 merge_vad \u662f\u5426\u5c06 VAD \u6a21\u578b\u5207\u5272\u7684\u77ed\u97f3\u9891\u788e\u7247\u5408\u6210\uff0c\u5408\u5e76\u540e\u957f\u5ea6\u4e3a <code>merge_length_s</code>\uff0c\u5355\u4f4d\u4e3a\u79d2\u3002 use_itn \u8f93\u51fa\u7ed3\u679c\u4e2d\u662f\u5426\u5305\u542b\u6807\u70b9\u4e0e\u9006\u6587\u672c\u6b63\u5219\u5316\u3002 ban_emo_unk \u7981\u7528 <code>emo_unk</code> \u6807\u7b7e\uff0c\u7981\u7528\u540e\u6240\u6709\u7684\u53e5\u5b50\u90fd\u4f1a\u88ab\u8d4b\u4e0e\u60c5\u611f\u6807\u7b7e\u3002 beam_size decoding_ctc_weight <p>\u957f\u97f3\u9891\u5185\u5b58\u6ea2\u51fa\u95ee\u9898</p> <p>\u8f93\u5165\u4e3a\u957f\u97f3\u9891\uff0c\u8fd0\u884c\u65f6\u9047\u5230 OOM \u95ee\u9898\uff0c\u901a\u5e38\u662f\u56e0\u4e3a\u663e\u5b58\u5360\u7528\u4e0e\u97f3\u9891\u65f6\u957f\u5448\u5e73\u65b9\u5173\u7cfb\u589e\u52a0\uff0c\u4e00\u822c\u5206\u4e3a 3 \u79cd\u60c5\u51b5:</p> <ul> <li>\u63a8\u7406\u8d77\u59cb\u9636\u6bb5\uff0c\u663e\u5b58\u4e3b\u8981\u53d6\u51b3\u4e8e <code>batch_size_s</code>\uff0c\u9002\u5f53\u51cf\u5c0f\u8be5\u503c\uff0c\u53ef\u4ee5\u51cf\u5c11\u663e\u5b58\u5360\u7528\u3002</li> <li>\u63a8\u7406\u4e2d\u95f4\u9636\u6bb5\uff0c\u9047\u5230 VAD \u5207\u5272\u7684\u957f\u97f3\u9891\u7247\u6bb5\uff0c\u603b token \u6570\u5c0f\u4e8e <code>batch_size_s</code>\uff0c\u4ecd\u7136\u51fa\u73b0 OOM\uff0c\u53ef\u4ee5\u9002\u5f53\u51cf\u5c0f <code>batch_size_threshold_s</code>\uff0c\u8d85\u8fc7\u9608\u503c\u5f3a\u5236 batch \u4e3a 1\u3002</li> <li>\u63a8\u7406\u5feb\u7ed3\u675f\u9636\u6bb5\uff0c\u9047\u5230 VAD \u5207\u5272\u7684\u957f\u97f3\u9891\u7247\u6bb5\uff0c\u603b token \u6570\u5c0f\u4e8e <code>batch_size_s</code>\uff0c\u4e14\u8d85\u8fc7\u9608\u503c<code>batch_size_threshold_s</code>\uff0c\u5f3a\u5236 batch \u4e3a 1\u3002\u4ecd\u7136\u51fa\u73b0 OOM\uff0c\u53ef\u4ee5\u9002\u5f53\u51cf\u5c0f<code>max_single_segment_time</code>\uff0c\u4f7f\u5f97 VAD \u5207\u5272\u97f3\u9891\u65f6\u957f\u53d8\u77ed\u3002</li> </ul>"},{"location":"changelog/","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<ul> <li>2024/07/04: SenseVoice \u662f\u4e00\u4e2a\u57fa\u7840\u8bed\u97f3\u7406\u89e3\u6a21\u578b\uff0c\u5177\u5907\u591a\u79cd\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u6db5\u76d6\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u3001\u8bed\u8a00\u8bc6\u522b\uff08LID\uff09\u3001\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\u4ee5\u53ca\u97f3\u9891\u4e8b\u4ef6\u68c0\u6d4b\uff08AED\uff09\u3002</li> <li>2024/07/01: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 GPU \u7248\u672c 1.1 \u53d1\u5e03\uff0c\u4f18\u5316 bladedisc \u6a21\u578b\u517c\u5bb9\u6027\u95ee\u9898\u3002</li> <li>2024/06/27: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 GPU \u7248\u672c 1.0 \u53d1\u5e03\uff0c\u652f\u6301\u52a8\u6001 batch\uff0c\u652f\u6301\u591a\u8def\u5e76\u53d1\uff0c\u5728\u957f\u97f3\u9891\u6d4b\u8bd5\u96c6\u4e0a\u5355\u7ebf RTF \u4e3a 0.0076\uff0c\u591a\u7ebf\u52a0\u901f\u6bd4\u4e3a 1200+\uff08CPU \u4e3a 330+\uff09\u3002</li> <li>2024/05/15: \u65b0\u589e\u52a0\u60c5\u611f\u8bc6\u522b\u6a21\u578b emotion2vec+large\u3001emotion2vec+base\u3001emotion2vec+seed\uff0c\u8f93\u51fa\u60c5\u611f\u7c7b\u522b\u4e3a\uff1a\u751f\u6c14/angry\uff0c\u5f00\u5fc3/happy\uff0c\u4e2d\u7acb/neutral\uff0c\u96be\u8fc7/sad\u3002</li> <li>2024/05/15: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 4.5\u3001\u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 1.6\u3001\u4e2d\u6587\u5b9e\u65f6\u8bed\u97f3\u542c\u5199\u670d\u52a1 1.10 \u53d1\u5e03\uff0c\u9002\u914d FunASR 1.0 \u6a21\u578b\u7ed3\u6784\u3002</li> <li>2024/03/05: \u65b0\u589e\u52a0 Qwen-Audio \u4e0e Qwen-Audio-Chat \u97f3\u9891\u6587\u672c\u6a21\u6001\u5927\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u97f3\u9891\u9886\u57df\u6d4b\u8bd5\u699c\u5355\u5237\u699c\uff0c\u4e2d\u652f\u6301\u8bed\u97f3\u5bf9\u8bdd\uff0c\u8be6\u7ec6\u7528\u6cd5\u89c1\u793a\u4f8b\u3002</li> <li>2024/03/05: \u65b0\u589e\u52a0 Whisper-large-v3 \u6a21\u578b\u652f\u6301\uff0c\u591a\u8bed\u8a00\u8bed\u97f3\u8bc6\u522b/\u7ffb\u8bd1/\u8bed\u79cd\u8bc6\u522b\uff0c\u652f\u6301\u4ece modelscope \u4ed3\u5e93\u4e0b\u8f7d\uff0c\u4e5f\u652f\u6301\u4ece OpenAI \u4ed3\u5e93\u4e0b\u8f7d\u6a21\u578b\u3002</li> <li>2024/03/05: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 4.4\u3001\u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 1.5\u3001\u4e2d\u6587\u5b9e\u65f6\u8bed\u97f3\u542c\u5199\u670d\u52a1 1.9 \u53d1\u5e03\uff0cdocker\u955c\u50cf\u652f\u6301 arm64 \u5e73\u53f0\uff0c\u5347\u7ea7 modelscope \u7248\u672c\u3002</li> <li>2024/01/30: FunASR 1.0 \u53d1\u5e03\u3002</li> <li>2024/01/30: \u65b0\u589e\u52a0\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u94fe\u63a5\uff0c\u539f\u59cb\u6a21\u578b repo.</li> <li>2024/01/25: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 4.2\u3001\u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 1.3\uff0c\u4f18\u5316 vad \u6570\u636e\u5904\u7406\u65b9\u5f0f\uff0c\u5927\u5e45\u964d\u4f4e\u5cf0\u503c\u5185\u5b58\u5360\u7528\uff0c\u5185\u5b58\u6cc4\u6f0f\u4f18\u5316\uff1b\u4e2d\u6587\u5b9e\u65f6\u8bed\u97f3\u542c\u5199\u670d\u52a1 1.7 \u53d1\u5e03\uff0c\u5ba2\u6237\u7aef\u4f18\u5316\u3002</li> <li>2024/01/09: funasr \u793e\u533a\u8f6f\u4ef6\u5305 windows 2.0 \u7248\u672c\u53d1\u5e03\uff0c\u652f\u6301\u8f6f\u4ef6\u5305\u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199 4.1\u3001\u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u51991.2\u3001\u4e2d\u6587\u5b9e\u65f6\u542c\u5199\u670d\u52a11.6\u7684\u6700\u65b0\u529f\u80fd\uff0c\u8be6\u7ec6\u4fe1\u606f\u53c2\u9605 FunASR\u793e\u533a\u8f6f\u4ef6\u5305windows\u7248\u672c\u3002</li> <li>2024/01/03: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 4.0 \u53d1\u5e03\uff0c\u65b0\u589e\u652f\u6301 8k \u6a21\u578b\u3001\u4f18\u5316\u65f6\u95f4\u6233\u4e0d\u5339\u914d\u95ee\u9898\u53ca\u589e\u52a0\u53e5\u5b50\u7ea7\u522b\u65f6\u95f4\u6233\u3001\u4f18\u5316\u82f1\u6587\u5355\u8bcd fst \u70ed\u8bcd\u6548\u679c\u3001\u652f\u6301\u81ea\u52a8\u5316\u914d\u7f6e\u7ebf\u7a0b\u53c2\u6570\uff0c\u540c\u65f6\u4fee\u590d\u5df2\u77e5\u7684 crash \u95ee\u9898\u53ca\u5185\u5b58\u6cc4\u6f0f\u95ee\u9898\u3002</li> <li>2024/01/03: \u4e2d\u6587\u5b9e\u65f6\u8bed\u97f3\u542c\u5199\u670d\u52a1 1.6 \u53d1\u5e03\uff0c2pass-offline \u6a21\u5f0f\u652f\u6301 Ngram \u8bed\u8a00\u6a21\u578b\u89e3\u7801\u3001wfst \u70ed\u8bcd\uff0c\u540c\u65f6\u4fee\u590d\u5df2\u77e5\u7684 crash \u95ee\u9898\u53ca\u5185\u5b58\u6cc4\u6f0f\u95ee\u9898\u3002</li> <li>2024/01/03: \u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 1.2 \u53d1\u5e03\uff0c\u4fee\u590d\u5df2\u77e5\u7684crash\u95ee\u9898\u53ca\u5185\u5b58\u6cc4\u6f0f\u95ee\u9898\u3002</li> <li>2023/12/04: FunASR \u793e\u533a\u8f6f\u4ef6\u5305 Windows 1.0 \u7248\u672c\u53d1\u5e03\uff0c\u652f\u6301\u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u3001\u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u3001\u4e2d\u6587\u5b9e\u65f6\u542c\u5199\u670d\u52a1\uff0c\u8be6\u7ec6\u4fe1\u606f\u53c2\u9605FunASR\u793e\u533a\u8f6f\u4ef6\u5305windows\u7248\u672c\u3002</li> <li>2023/11/08\uff1a\u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 3.0 CPU \u7248\u672c\u53d1\u5e03\uff0c\u65b0\u589e\u6807\u70b9\u5927\u6a21\u578b\u3001Ngram \u8bed\u8a00\u6a21\u578b \u4e0ewfst \u70ed\u8bcd\u3002</li> <li>2023/10/17: \u82f1\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1\u4e00\u952e\u90e8\u7f72\u7684 CPU \u7248\u672c\u53d1\u5e03\u3002</li> <li>2023/10/13: SlideSpeech: \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u97f3\u89c6\u9891\u8bed\u6599\u5e93\uff0c\u4e3b\u8981\u662f\u5728\u7ebf\u4f1a\u8bae\u6216\u8005\u5728\u7ebf\u8bfe\u7a0b\u573a\u666f\uff0c\u5305\u542b\u4e86\u5927\u91cf\u4e0e\u53d1\u8a00\u4eba\u8bb2\u8bdd\u5b9e\u65f6\u540c\u6b65\u7684\u5e7b\u706f\u7247\u3002</li> <li>2023.10.10: Paraformer-long-Spk \u6a21\u578b\u53d1\u5e03\uff0c\u652f\u6301\u5728\u957f\u8bed\u97f3\u8bc6\u522b\u7684\u57fa\u7840\u4e0a\u83b7\u53d6\u6bcf\u53e5\u8bdd\u7684\u8bf4\u8bdd\u4eba\u6807\u7b7e\u3002</li> <li>2023.10.07: FunCodec: FunCodec \u63d0\u4f9b\u5f00\u6e90\u6a21\u578b\u548c\u8bad\u7ec3\u5de5\u5177\uff0c\u53ef\u4ee5\u7528\u4e8e\u97f3\u9891\u79bb\u6563\u7f16\u7801\uff0c\u4ee5\u53ca\u57fa\u4e8e\u79bb\u6563\u7f16\u7801\u7684\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u5408\u6210\u7b49\u4efb\u52a1\u3002</li> <li>2023.09.01: \u4e2d\u6587\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1 2.0 CPU \u7248\u672c\u53d1\u5e03\uff0c\u65b0\u589e ffmpeg\u3001\u65f6\u95f4\u6233\u4e0e\u70ed\u8bcd\u6a21\u578b\u652f\u6301\u3002</li> <li>2023.08.07: \u4e2d\u6587\u5b9e\u65f6\u8bed\u97f3\u542c\u5199\u670d\u52a1\u4e00\u952e\u90e8\u7f72\u7684CPU\u7248\u672c\u53d1\u5e03\u3002</li> <li>2023.07.17: BAT \u4e00\u79cd\u4f4e\u5ef6\u8fdf\u4f4e\u5185\u5b58\u6d88\u8017\u7684 RNN-T \u6a21\u578b\u53d1\u5e03\u3002</li> <li>2023.06.26: ASRU2023 \u591a\u901a\u9053\u591a\u65b9\u4f1a\u8bae\u8f6c\u5f55\u6311\u6218\u8d5b 2.0 \u5b8c\u6210\u7ade\u8d5b\u7ed3\u679c\u516c\u5e03\uff0c\u8be6\u7ec6\u4fe1\u606f\u53c2\u9605\uff08M2MeT2.0\uff09</li> </ul> <ol> <li> <p>https://github.com/modelscope/FunASR/blob/main/README_zh.md \u21a9</p> </li> </ol>"},{"location":"cli/","title":"FunASR \u547d\u4ee4\u884c\u53c2\u6570","text":"<p>\u6210\u529f\u5b89\u88c5\u597d FunASR \u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u7ec8\u7aef\u4e2d\u76f4\u63a5\u4f7f\u7528 <code>funasr</code> \u547d\u4ee4\u4e86\u3002\u901a\u8fc7\u5728\u547d\u4ee4\u884c\u4e2d\u6307\u5b9a ASR\u3001VAD\u3001\u6807\u70b9\u6062\u590d\u7b49\u6a21\u578b\uff0c\u4fbf\u53ef\u4ee5\u5feb\u901f\u9a8c\u8bc1 FunASR \u7684\u6548\u679c</p> <pre><code>funasr  ++model=paraformer-zh \\\n        ++vad_model=\"fsmn-vad\" \\\n        ++punc_model=\"ct-punc\" \\\n        ++input=asr_example_zh.wav\n</code></pre> <p>\u66f4\u63a8\u8350\u4f7f\u7528 Python API \u65b9\u5f0f</p> <p>\u5982\u679c\u6240\u4f7f\u7528\u7684\u6a21\u578b\u672c\u5730\u4e0d\u5b58\u5728\uff0c\u90a3\u4e48\u8fc7\u7a0b\u4e2d FunASR \u4f1a\u5148\u4e0b\u8f7d\u5bf9\u5e94\u7684\u6a21\u578b\uff0c\u4f46\u6574\u4e2a\u8fc7\u7a0b\u7684\u54cd\u5e94\u65f6\u95f4\u8f83\u957f\u3002\u6b64\u5916\uff0c\u5c31\u7b97\u6b64\u524d\u5df2\u7ecf\u4e0b\u8f7d\u4e86\u76f8\u5e94\u6a21\u578b\uff0c\u518d\u6b21\u6267\u884c\u6b64\u547d\u4ee4\u4e5f\u9700\u8981\u7b49\u5f85\u8f83\u957f\u65f6\u95f4\u3002</p>"},{"location":"ct_punc/","title":"\u6807\u70b9\u6062\u590d","text":"<p>\u4f7f\u7528 SenseVoice \u6216\u8005 Paraformer ASR \u6a21\u578b\uff0c\u8f6c\u5199\u51fa\u6765\u7684\u6587\u672c\u90fd\u662f\u5b57\u7b26\u7ea7\u7684\uff0c\u6ca1\u6709\u4efb\u4f55\u6807\u70b9\u7b26\u53f7\u3002\u5e78\u8fd0\u7684\u662f\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 FunASR \u4e2d\u4f7f\u7528 ct-punc \u6a21\u578b\u6765\u4fee\u590d\u6807\u70b9\uff0c\u4f7f\u5f97\u8f6c\u5199\u51fa\u6765\u7684\u6587\u672c\u66f4\u6613\u4e8e\u9605\u8bfb\u3002</p> <pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"ct-punc\")\nres = model.generate(input=\"\u90a3\u4eca\u5929\u7684\u4f1a\u5c31\u5230\u8fd9\u91cc\u5427 happy new year \u660e\u5e74\u89c1\")\nprint(res)\n</code></pre>"},{"location":"deploy/","title":"\u670d\u52a1\u90e8\u7f72","text":""},{"location":"emotion/","title":"\u60c5\u7eea\u8bc6\u522b","text":"<pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"iic/emotion2vec_plus_large\")\nwav_file = f\"{model.model_path}/example/test.wav\"\nres = model.generate(wav_file, output_dir=\"./outputs\", granularity=\"utterance\", extract_embedding=False)\nprint(res)\n</code></pre>"},{"location":"export_model/","title":"\u5bfc\u51fa\u6a21\u578b","text":""},{"location":"export_model/#1","title":"1. \u547d\u4ee4\u884c\u5bfc\u51fa","text":"<pre><code>funasr-export ++model=paraformer ++quantize=false\n</code></pre>"},{"location":"export_model/#2-python","title":"2. Python \u5bfc\u51fa","text":"<pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"paraformer\")\nres = model.export(quantize=False)\n</code></pre>"},{"location":"export_model/#3-onnx","title":"3. \u6d4b\u8bd5 ONNX","text":"<p>\u9700\u8981\u5148\u5b89\u88c5\u597d <code>funasr-onnx</code> \u5e93\u3002</p> <pre><code>from funasr_onnx import Paraformer\n\nmodel_dir = \"damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\"\nmodel = Paraformer(model_dir, batch_size=1, quantize=True)\n\nwav_path = [\n    '~/.cache/modelscope/hub/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/example/asr_example.wav'\n    ]\n\nresult = model(wav_path)\nprint(result)\n</code></pre> <ol> <li> <p>ONNXRuntime-Python: https://github.com/modelscope/FunASR/tree/main/runtime/python/onnxruntime \u21a9</p> </li> </ol>"},{"location":"fa/","title":"\u65f6\u95f4\u6233\u9884\u6d4b","text":"<p>\u65f6\u95f4\u6233\u9884\u6d4b\u662f\u6307\u8f6c\u5199\u540e\u7684\u6bcf\u4e2a\u5b57\u7b26\u5bf9\u5e94\u5230\u97f3\u9891\u7247\u6bb5\u7684\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\uff0c\u6211\u4eec\u9700\u8981\u63d0\u4f9b\u8f93\u5165\u97f3\u9891\u4ee5\u53ca\u8f6c\u5199\u540e\u7684\u6587\u672c\u3002</p> <pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"fa-zh\")\nwav_file = f\"{model.model_path}/example/asr_example.wav\"\ntext_file = f\"{model.model_path}/example/text.txt\"  # (1)!\nres = model.generate(input=(wav_file, text_file), data_type=(\"sound\", \"text\"))\nprint(res)\n</code></pre> <ol> <li>\u5b9e\u9645\u6587\u672c\u5e76\u6ca1\u6709\u7a7a\u683c\u95f4\u9694\u6bcf\u4e2a\u5b57\u7b26\uff0c\u9700\u8981\u4e0e\u8f93\u51fa\u7ed3\u679c\u4e2d\u7684 <code>text</code> \u533a\u522b\u5f00\u6765\u3002</li> </ol> <p>\u8f93\u51fa\u7ed3\u679c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e3a\u6587\u672c\u5b57\u7b26\u7684\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u3002</p> \u8f93\u51fa\u7ed3\u679c<pre><code>[\n  {\n    'key': 'rand_key_2yW4Acq9GFz6Y',\n    'text': '\u6b22 \u8fce \u5927 \u5bb6 \u6765 \u5230 \u9b54 \u642d \u793e \u533a \u8fdb \u884c \u4f53 \u9a8c',\n    'timestamp': [\n      [1190, 1410],\n      [1410, 1610],\n      [1610, 1830],\n      [1830, 2010],\n      [2010, 2230],\n      [2230, 2430],\n      [2430, 2650],\n      [2650, 2890],\n      [2890, 3130],\n      [3130, 3370],\n      [3410, 3650],\n      [3690, 3930],\n      [3950, 4190],\n      [4230, 4395]\n      ]\n  }\n]\n</code></pre>"},{"location":"installation/","title":"\u5b89\u88c5","text":""},{"location":"installation/#1-pip","title":"1. PIP","text":"<p>\u5efa\u8bae\u5148\u521b\u5efa\u4e00\u4e2a\u865a\u62df\u73af\u5883\uff0c\u907f\u514d\u5e72\u6270\u7cfb\u7edf\u73af\u5883</p> <pre><code>pip install torch torchaudio funasr  # (1)!\n</code></pre> <ol> <li>\u5982\u679c\u662f\u56fd\u5185\u7528\u6237\uff0c\u5efa\u8bae\u4f7f\u7528\u52a0\u4e0a <code>-i https://mirror.sjtu.edu.cn/pypi/web/simple</code> \u6765\u52a0\u5feb\u4e0b\u8f7d\u901f\u5ea6\uff0c\u5426\u5219\u6574\u4e2a\u4e0b\u8f7d\u8fc7\u7a0b\u4f1a\u5f88\u6162\u3002</li> </ol> <p>\u5982\u679c\u9700\u8981\u4f7f\u7528\u5de5\u4e1a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd8\u9700\u8981\u5b89\u88c5 modelscope \u4e0e huggingface_hub\u3002</p> <pre><code>pip install -U modelscope huggingface huggingface_hub\n</code></pre> <p>\u6b64\u5916\uff0c\u56e0\u4e3a FunASR \u4f9d\u8d56 ffmpeg \u5bf9\u97f3\u9891\u8fdb\u884c\u5904\u7406\uff0c\u5982\u679c\u4f60\u4f7f\u7528\u7684 conda \u73af\u5883\uff0c\u6211\u4eec\u5efa\u8bae\u60a8\u5728 conda \u73af\u5883\u4e2d\u5b89\u88c5 ffmpeg:</p> <pre><code>conda install ffmpeg\n</code></pre>"},{"location":"installation/#2","title":"2. \u6e90\u7801","text":"<p>\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4 FunASR \u6e90\u7801\u5b89\u88c5:</p> <pre><code>git clone https://github.com/alibaba/FunASR.git &amp;&amp; cd FunASR\npip3 install -e ./\n</code></pre>"},{"location":"installation/#3-docker","title":"3. Docker","text":"<p>\u5b89\u88c5 Docker</p> Ubuntu <pre><code>curl -fsSL https://test.docker.com -o test-docker.sh\nsudo sh test-docker.sh\n</code></pre> Debian <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> CentOSMacOS <pre><code>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\n</code></pre> <pre><code>brew install --cask --appdir=/Applications docker\n</code></pre>"},{"location":"installation/#31-funasr","title":"3.1 FunASR \u955c\u50cf","text":"<p>FunASR \u63d0\u4f9b\u4e86 CPU \u548c GPU \u7248\u672c\u7684 Docker \u955c\u50cf\uff1a</p> <ul> <li>CPU: registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.1</li> <li>GPU: registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-py38-torch1.11.0-tf1.15.5-1.8.1</li> </ul> <p>\u4f7f\u7528 <code>docker pull &lt;image-name&gt;:&lt;tag&gt;</code> \u547d\u4ee4\u6765\u62c9\u53d6\u955c\u50cf\u3002</p>"},{"location":"installation/#32","title":"3.2 \u542f\u52a8\u670d\u52a1","text":"<p>CPU \u955c\u50cf\u4e0e GPU \u955c\u50cf\u7684\u542f\u52a8\u65b9\u5f0f\u7565\u6709\u5dee\u5f02\uff0c\u9700\u8981\u53bb\u6389 <code>--gpus all</code> \u8fd9\u4e00\u884c\u3002</p> \u542f\u52a8FunASR CPU\u955c\u50cf<pre><code>sudo docker run -itd \\\n  --gpus all \\  # \u4f7f\u7528 GPU\n  --name funasr \\\n  -v &lt;local_dir:dir_in_docker&gt; &lt;image-name&gt;:&lt;tag&gt; /bin/bash\n\nsudo docker exec -it funasr /bin/bash\n</code></pre>"},{"location":"installation/#33","title":"3.3 \u505c\u6b62\u670d\u52a1","text":"<pre><code>docker ps  # \u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u955c\u50cf\ndocker stop funasr\n</code></pre>"},{"location":"installation/#4","title":"4. \u5e38\u89c1\u95ee\u9898","text":""},{"location":"installation/#41-mac-m1","title":"4.1 Mac M1 \u5b89\u88c5\u4e0d\u517c\u5bb9","text":"<p>\u5982\u679c\u5728 Mac M1 \u4e0a\u51fa\u73b0 \u201cmach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)\u201d \u9519\u8bef\uff0c\u9700\u8981\u5378\u8f7d\u6389 <code>cffi</code>\u3001<code>pycparser</code> \u5e93\u91cd\u65b0\u5b89\u88c5\u3002</p> <pre><code>pip uninstall cffi pycparser\nARCHFLAGS=\"-arch arm64\"\npip install cffi pycparser --compile --no-cache-dir\n</code></pre>"},{"location":"model_repo/","title":"\u6a21\u578b\u4ed3\u5e93","text":"<p>FunASR\u5f00\u6e90\u4e86\u5927\u91cf\u5728\u5de5\u4e1a\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u60a8\u53ef\u4ee5\u5728\u6a21\u578b\u8bb8\u53ef\u534f\u8bae\u4e0b\u81ea\u7531\u4f7f\u7528\u3001\u590d\u5236\u3001\u4fee\u6539\u548c\u5206\u4eab FunASR \u6a21\u578b\uff0c\u4e0b\u9762\u5217\u4e3e\u4ee3\u8868\u6027\u7684\u6a21\u578b\u3002</p> <p>\ud83e\udd17 \u8868\u793aHuggingface\u6a21\u578b\u4ed3\u5e93\uff0c\ud83c\udf40\u8868\u793aOpenAI\u6a21\u578b\u4ed3\u5e93</p>"},{"location":"model_repo/#1","title":"1. \u8bed\u97f3\u8bc6\u522b\u6a21\u578b","text":""},{"location":"model_repo/#11","title":"1.1 \u5176\u4ed6\u6a21\u578b","text":"\u6a21\u578b \u4efb\u52a1\u8be6\u60c5 \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf SenseVoiceSmall \ud83e\udd17 \u591a\u79cd\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u6db5\u76d6\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u3001\u8bed\u8a00\u8bc6\u522b\uff08LID\uff09\u3001\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\u4ee5\u53ca\u97f3\u9891\u4e8b\u4ef6\u68c0\u6d4b\uff08AED\uff09 400000\u5c0f\u65f6\uff0c\u4e2d\u6587 330M Whisper-large-v3 \ud83c\udf40 \u8bed\u97f3\u8bc6\u522b\uff0c\u5e26\u65f6\u95f4\u6233\u8f93\u51fa\uff0c\u975e\u5b9e\u65f6 \u591a\u8bed\u8a00 1550 M Qwen-Audio \ud83e\udd17 \u97f3\u9891\u6587\u672c\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08\u9884\u8bad\u7ec3\uff09 \u591a\u8bed\u8a00 8B Qwen-Audio-Chat \ud83e\udd17 \u97f3\u9891\u6587\u672c\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08chat\u7248\u672c\uff09 \u591a\u8bed\u8a00 8B Emotion2vec+large \ud83e\udd17 \u60c5\u611f\u8bc6\u522b\u6a21\u578b 40000\u5c0f\u65f6\uff0c4\u79cd\u60c5\u611f\u7c7b\u522b 300M"},{"location":"model_repo/#12-paraformer","title":"1.2 Paraformer \u6a21\u578b","text":"\u6a21\u578b\u540d\u5b57 \u4efb\u52a1\u8be6\u60c5 \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf \u8bcd\u5178\u5927\u5c0f \u662f\u5426\u5b9e\u65f6 SeACoParaformer-zh \u5e26\u70ed\u8bcd\u529f\u80fd\u7684\u8bed\u97f3\u8bc6\u522b\uff0c\u5e26\u65f6\u95f4\u6233\u8f93\u51fa 60000\u5c0f\u65f6\uff0c\u4e2d\u6587 220M \u975e\u5b9e\u65f6 Paraformer-zh \ud83e\udd17 \u80fd\u591f\u5904\u7406\u4efb\u610f\u957f\u5ea6\u7684\u8f93\u5165wav\u6587\u4ef6 60000\u5c0f\u65f6\uff0c\u4e2d\u6587 220M 8404 \u975e\u5b9e\u65f6 Paraformer-large-Spk \u5206\u89d2\u8272\u8bed\u97f3\u8bc6\u522b\uff0c\u5728\u957f\u97f3\u9891\u529f\u80fd\u7684\u57fa\u7840\u4e0a\u6dfb\u52a0\u8bf4\u8bdd\u4eba\u8bc6\u522b\u529f\u80fd\uff0c\u5e26\u65f6\u95f4\u6233\u8f93\u51fa 60000\u5c0f\u65f6\uff0c\u4e2d\u6587 220M \u975e\u5b9e\u65f6 Paraformer-large \u8f93\u5165 wav \u6587\u4ef6\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2 \u4e2d\u6587\u548c\u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e\uff0860000\u5c0f\u65f6\uff09 220M 8404 \u975e\u5b9e\u65f6 Paraformer-zh-streaming \ud83e\udd17 \u5904\u7406\u6d41\u5f0f\u8f93\u5165 60000\u5c0f\u65f6\uff0c\u4e2d\u6587 220M 8404 \u5b9e\u65f6 Paraformer-zh-Streaming-Small \u5904\u7406\u6d41\u5f0f\u8f93\u5165 60000\u5c0f\u65f6\uff0c\u4e2d\u6587 220M 8404 \u5b9e\u65f6 Paraformer-large-en \u957f\u97f3\u9891\u7248\u672c \ud83e\udd17 \u80fd\u591f\u5904\u7406\u4efb\u610f\u957f\u5ea6\u7684\u8f93\u5165wav\u6587\u4ef6 \u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e\uff0850000\u5c0f\u65f6\uff09 220M 10020 \u975e\u5b9e\u65f6 Paraformer-large \u70ed\u8bcd \u57fa\u4e8e\u6fc0\u52b1\u589e\u5f3a\u7684\u70ed\u8bcd\u5b9a\u5236\u652f\u6301\uff0c\u53ef\u4ee5\u63d0\u9ad8\u70ed\u8bcd\u7684\u53ec\u56de\u7387\u548c\u51c6\u786e\u7387\uff0c\u8f93\u5165wav\u6587\u4ef6\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2 \u4e2d\u6587\u548c\u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e\uff0860000\u5c0f\u65f6\uff09 220M 8404 \u975e\u5b9e\u65f6 Paraformer \u8f93\u5165 wav \u6587\u4ef6\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2 \u4e2d\u6587\u548c\u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e\uff0850000\u5c0f\u65f6\uff09 68M 8358 \u79bb\u7ebf Paraformer-tiny \u8f7b\u91cf\u7ea7Paraformer\u6a21\u578b\uff0c\u652f\u6301\u666e\u901a\u8bdd\u547d\u4ee4\u8bcd\u8bc6\u522b \u4e2d\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (200hours) 5.2M 544 \u975e\u5b9e\u65f6 Paraformer-aishell \u5b66\u672f\u6a21\u578b \u4e2d\u6587\uff0cAISHELL (178hours) 43M 4234 \u975e\u5b9e\u65f6 ParaformerBert-aishell \u5b66\u672f\u6a21\u578b \u4e2d\u6587\uff0cAISHELL (178hours) 43M 4234 \u975e\u5b9e\u65f6 Paraformer-aishell2 \u5b66\u672f\u6a21\u578b \u4e2d\u6587\uff0cAISHELL-2 (1000hours) 64M 5212 \u975e\u5b9e\u65f6 ParaformerBert-aishell2 \u5b66\u672f\u6a21\u578b \u4e2d\u6587\uff0cAISHELL-2 (1000hours) 64M 5212 \u975e\u5b9e\u65f6"},{"location":"model_repo/#13-uniasr","title":"1.3 UniASR \u6a21\u578b","text":"\u6a21\u578b\u540d\u5b57 \u8bad\u7ec3\u6570\u636e \u8bcd\u5178\u91cf \u53c2\u6570\u91cf \u662f\u5426\u5b9e\u65f6 \u5907\u6ce8 UniASR \u4e2d\u6587\u548c\u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (60000 \u5c0f\u65f6) 8358 100M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR-large \u4e2d\u6587\u548c\u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (60000 \u5c0f\u65f6) 8358 220M \u975e\u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR English \u82f1\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (10000 \u5c0f\u65f6) 1080 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Russian \u4fc4\u8bed\uff0c \u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (5000 \u5c0f\u65f6) 1664 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Japanese \u65e5\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (5000 \u5c0f\u65f6) 5977 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Korean \u97e9\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (2000 \u5c0f\u65f6) 6400 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Cantonese (CHS) \u7ca4\u8bed\uff08\u7b80\u4f53\u4e2d\u6587\uff09\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (5000 \u5c0f\u65f6) 1468 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Indonesian \u5370\u5c3c\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1067 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Vietnamese \u8d8a\u5357\u8bed \u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1001 95M \u5b9e\u65f6 UniASR Spanish \u897f\u73ed\u7259\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 3445 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Portuguese \u8461\u8404\u7259\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1617 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR French \u6cd5\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 3472 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR German \u5fb7\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 3690 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Persian \u6ce2\u65af\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1257 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Burmese \u7f05\u7538\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 696 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Hebrew \u5e0c\u4f2f\u6765\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1085 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Urdu \u4e4c\u5c14\u90fd\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 877 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b UniASR Turkish \u571f\u8033\u5176\u8bed\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (1000 \u5c0f\u65f6) 1582 95M \u5b9e\u65f6 \u6d41\u5f0f\u79bb\u7ebf\u4e00\u4f53\u5316\u6a21\u578b"},{"location":"model_repo/#14-conformer","title":"1.4 Conformer \u6a21\u578b","text":"\u6a21\u578b\u540d\u5b57 \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf \u8bcd\u5178\u5927\u5c0f \u662f\u5426\u5b9e\u65f6 \u5907\u6ce8 Conformer-en \ud83e\udd17 50000\u5c0f\u65f6\uff0c\u82f1\u6587 220M 4199 \u975e\u5b9e\u65f6 Conformer \u4e2d\u6587\uff0cAISHELL (178hours) 44M 4234 \u975e\u5b9e\u65f6 \u8f93\u5165wav\u6587\u4ef6\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2 Conformer \u4e2d\u6587\uff0cAISHELL-2 (1000hours) 44M 5212 \u975e\u5b9e\u65f6 \u8f93\u5165wav\u6587\u4ef6\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2"},{"location":"model_repo/#2","title":"2. \u591a\u8bf4\u8bdd\u4eba\u8bed\u97f3\u8bc6\u522b\u6a21\u578b","text":"\u6a21\u578b\u540d\u5b57 \u8bad\u7ec3\u6570\u636e \u8bcd\u5178\u91cf \u53c2\u6570\u91cf \u975e\u5b9e\u65f6/\u5b9e\u65f6 \u5907\u6ce8 MFCCA \u4e2d\u6587\uff0c AliMeeting\u3001AISHELL-4\u3001Simudata (917hours) 4950 45M \u975e\u5b9e\u65f6 \u8f93\u5165\u97f3\u9891\u7684\u6301\u7eed\u65f6\u95f4\u4e0d\u8d85\u8fc720\u79d2\uff0c\u8f93\u5165\u97f3\u9891\u7684\u901a\u9053\u6570\u4e0d\u8d85\u8fc78\u901a\u9053\u3002"},{"location":"model_repo/#3","title":"3. \u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b\u6a21\u578b","text":"\u6a21\u578b\u540d\u5b57 \u8bad\u7ec3\u6570\u636e \u6a21\u578b\u53c2\u6570 \u91c7\u6837\u7387 \u5b9e\u65f6 FSMN-VAD \ud83e\udd17 \u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (5000hours) 0.4M 16000 \u5b9e\u65f6 FSMN-VAD \u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (5000hours) 0.4M 8000 \u5b9e\u65f6"},{"location":"model_repo/#4","title":"4. \u6807\u70b9\u6062\u590d\u6a21\u578b","text":"\u6a21\u578b \u4efb\u52a1\u8be6\u60c5 \u8bad\u7ec3\u6570\u636e \u6a21\u578b\u53c2\u6570 \u8bcd\u5178\u5927\u5c0f \u975e\u5b9e\u65f6/\u5b9e\u65f6 CT-Transformer-Large \u652f\u6301\u4e2d\u82f1\u6587\u6807\u70b9\u5927\u6a21\u578b \u4e2d\u6587\u548c\u82f1\u6587\uff0cAlibaba Text Data(100M) 1.1G 471067 \u975e\u5b9e\u65f6 CT-Transformer \u652f\u6301\u4e2d\u82f1\u6587\u6807\u70b9 \u4e2d\u6587\u548c\u82f1\u6587\uff0cAlibaba Text Data(70M) 291M 272727 \u975e\u5b9e\u65f6 CT-Transformer-Realtime VAD\u70b9\u5b9e\u65f6\u6807\u70b9 \u4e2d\u6587\u548c\u82f1\u6587\uff0cAlibaba Text Data(70M) 288M 272727 \u5b9e\u65f6 ct-punc \ud83e\udd17 \u6807\u70b9\u6062\u590d 100M\uff0c\u4e2d\u6587\u4e0e\u82f1\u6587 290M"},{"location":"model_repo/#5","title":"5. \u8bed\u97f3\u6a21\u578b","text":"\u6a21\u578b \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf \u8bcd\u5178\u5927\u5c0f Transformer \u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e 57M 8404"},{"location":"model_repo/#6","title":"6. \u8bf4\u8bdd\u4eba\u786e\u8ba4\u6a21\u578b","text":"\u6a21\u578b \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf Xvector \u4e2d\u6587\uff0cCNCeleb (1,200 \u5c0f\u65f6)\uff0c3465 \u8bf4\u8bdd\u4eba 17.5M Xvector \u82f1\u6587\uff0cCallHome (60 \u5c0f\u65f6)\uff0c6135 \u8bf4\u8bdd\u4eba 61M cam++  \u2b50 \ud83e\udd17 5000\u5c0f\u65f6 7.2M"},{"location":"model_repo/#7","title":"7. \u8bf4\u8bdd\u4eba\u65e5\u5fd7\u6a21\u578b","text":"\u6a21\u578b \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf SOND \u4e2d\u6587\uff0cAliMeeting (120 \u5c0f\u65f6) 40.5M SOND \u82f1\u6587\uff0cCallHome (60 \u5c0f\u65f6) 12M"},{"location":"model_repo/#8","title":"8. \u65f6\u95f4\u6233\u9884\u6d4b\u6a21\u578b","text":"\u6a21\u578b \u8bad\u7ec3\u6570\u636e \u53c2\u6570\u91cf TP-Aligner \u4e2d\u6587\uff0c\u963f\u91cc\u5df4\u5df4\u8bed\u97f3\u6570\u636e (50000hours) 37.8M fa-zh  \u2b50 \ud83e\udd17 50000 \u5c0f\u65f6\uff0c\u4e2d\u6587 38M"},{"location":"model_repo/#9","title":"9. \u9006\u6587\u672c\u6b63\u5219\u5316","text":"\u6a21\u578b\u540d\u5b57 \u8bed\u8a00 \u6a21\u578b\u53c2\u6570 \u5907\u6ce8 English EN 1.54M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Russian RU 17.79M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Japanese JA 6.8M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Korean KO 1.28M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Indonesian ID 2.06M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Vietnamese VI 0.92M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Tagalog TL 0.65M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Spanish ES 1.32M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 Portuguese PT 1.28M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 French FR 4.39M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406 German GE 3.95M ITN\uff0c\u8bed\u97f3\u8bc6\u522b\u6587\u672c\u540e\u5904\u7406"},{"location":"offline_transcribe/","title":"\u79bb\u7ebf\u8f6c\u5199","text":""},{"location":"reference/","title":"\u53c2\u8003","text":""},{"location":"reference/#1","title":"1. \u8bba\u6587","text":""},{"location":"reference/#11","title":"1.1 \u8bed\u97f3\u8bc6\u522b","text":"<ul> <li>FunASR: A Fundamental End-to-End Speech Recognition Toolkit, INTERSPEECH 2023</li> <li>BAT: Boundary aware transducer for memory-efficient and low-latency ASR, INTERSPEECH 2023</li> <li>Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition, INTERSPEECH 2022</li> <li>E-branchformer: Branchformer with enhanced merging for speech recognition, SLT 2022</li> <li>Branchformer: Parallel mlp-attention architectures to capture local and global context for speech recognition and understanding, ICML 2022</li> <li>Universal ASR: Unifying Streaming and Non-Streaming ASR Using a Single Encoder-Decoder Model, arXiv preprint arXiv:2010.14099, 2020</li> <li>San-m: Memory equipped self-attention for end-to-end speech recognition, INTERSPEECH 2020</li> <li>Streaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition, INTERSPEECH 2020</li> <li>Conformer: Convolution-augmented Transformer for Speech Recognition,  INTERSPEECH 2020</li> <li>Sequence-to-sequence learning with Transducers, NIPS 2016</li> </ul>"},{"location":"reference/#12","title":"1.2 \u591a\u4eba\u8bed\u97f3\u8bc6\u522b","text":"<ul> <li>MFCCA:Multi-Frame Cross-Channel attention for multi-speaker ASR in Multi-party meeting scenario, ICASSP 2022</li> </ul>"},{"location":"reference/#13","title":"1.3 \u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b","text":"<ul> <li>Deep-FSMN for Large Vocabulary Continuous Speech Recognition, ICASSP 2018</li> </ul>"},{"location":"reference/#14","title":"1.4 \u6807\u70b9\u6062\u590d","text":"<ul> <li>CT-Transformer: Controllable time-delay transformer for real-time punctuation prediction and disfluency detection, ICASSP 2018</li> </ul>"},{"location":"reference/#15","title":"1.5 \u8bed\u8a00\u6a21\u578b","text":"<ul> <li>Attention Is All You Need, NEURIPS 2017</li> </ul>"},{"location":"reference/#16","title":"1.6 \u8bf4\u8bdd\u4eba\u9a8c\u8bc1","text":"<ul> <li>X-VECTORS: ROBUST DNN EMBEDDINGS FOR SPEAKER RECOGNITION, ICASSP 2018</li> </ul>"},{"location":"reference/#17","title":"1.7 \u8bf4\u8bdd\u4eba\u5206\u7c7b","text":"<ul> <li>Speaker Overlap-aware Neural Diarization for Multi-party Meeting Analysis, EMNLP 2022</li> <li>TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization, ICASSP 2023</li> </ul>"},{"location":"reference/#18","title":"1.8 \u65f6\u95f4\u6233\u9884\u6d4b","text":"<ul> <li>Achieving Timestamp Prediction While Recognizing with Non-Autoregressive End-to-End ASR Model, arXiv:2301.12343</li> </ul>"},{"location":"sdk_offline_transcription/","title":"FunASR \u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1","text":"<p>FunASR \u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u8f6f\u4ef6\u5305\uff0c\u63d0\u4f9b\u4e86\u4e00\u6b3e\u529f\u80fd\u5f3a\u5927\u7684\u8bed\u97f3\u79bb\u7ebf\u6587\u4ef6\u8f6c\u5199\u670d\u52a1\u3002\u62e5\u6709\u5b8c\u6574\u7684\u8bed\u97f3\u8bc6\u522b\u94fe\u8def\uff0c\u7ed3\u5408\u4e86\u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b\u3001\u8bed\u97f3\u8bc6\u522b\u3001\u6807\u70b9\u7b49\u6a21\u578b\uff0c\u53ef\u4ee5\u5c06\u51e0\u5341\u4e2a\u5c0f\u65f6\u7684\u957f\u97f3\u9891\u4e0e\u89c6\u9891\u8bc6\u522b\u6210\u5e26\u6807\u70b9\u7684\u6587\u5b57\uff0c\u800c\u4e14\u652f\u6301\u4e0a\u767e\u8def\u8bf7\u6c42\u540c\u65f6\u8fdb\u884c\u8f6c\u5199\u3002</p> <p>FunASR \u53ef\u4ee5\u8f93\u51fa\u4e3a\u5e26\u6807\u70b9\u7684\u6587\u5b57\uff0c\u542b\u6709\u5b57\u7ea7\u522b\u65f6\u95f4\u6233\uff0c\u652f\u6301 ITN \u4e0e\u7528\u6237\u81ea\u5b9a\u4e49\u70ed\u8bcd\u7b49\u3002\u670d\u52a1\u7aef\u96c6\u6210\u6709 FFMPEG\uff0c\u652f\u6301\u5404\u79cd\u97f3\u89c6\u9891\u683c\u5f0f\u8f93\u5165\u3002\u8f6f\u4ef6\u5305\u63d0\u4f9b\u6709 Html\u3001Python\u3001C++\u3001Java \u4e0e C# \u7b49\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u5ba2\u6237\u7aef\uff0c\u7528\u6237\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u4e0e\u8fdb\u4e00\u6b65\u5f00\u53d1\u3002</p> <p></p>"},{"location":"sdk_offline_transcription/#1","title":"1. \u7248\u672c\u53d1\u5e03","text":"\u65f6\u95f4 \u8be6\u60c5 \u955c\u50cf\u7248\u672c \u955c\u50cfID 2024.05.15 \u9002\u914dFunASR 1.0\u6a21\u578b\u7ed3\u6784 funasr-runtime-sdk-cpu-0.4.5 058b9882ae67 2024.03.05 Docker \u955c\u50cf\u652f\u6301 Arm64 \u5e73\u53f0\uff0c\u5347\u7ea7 ModelScope \u7248\u672c funasr-runtime-sdk-cpu-0.4.4 2dc87b86dc49 2024.01.25 \u4f18\u5316 vad \u6570\u636e\u5904\u7406\u65b9\u5f0f\uff0c\u5927\u5e45\u964d\u4f4e\u5cf0\u503c\u5185\u5b58\u5360\u7528\uff1b\u5185\u5b58\u6cc4\u6f0f\u4f18\u5316 funasr-runtime-sdk-cpu-0.4.2 befdc7b179ed 2024.01.08 \u4f18\u5316\u53e5\u5b50\u7ea7\u65f6\u95f4\u6233 Json \u683c\u5f0f funasr-runtime-sdk-cpu-0.4.1 0250f8ef981b 2024.01.03 \u65b0\u589e\u652f\u6301 8k \u6a21\u578b\u3001\u4f18\u5316\u65f6\u95f4\u6233\u4e0d\u5339\u914d\u95ee\u9898\u53ca\u589e\u52a0\u53e5\u5b50\u7ea7\u522b\u65f6\u95f4\u6233\u3001\u4f18\u5316\u82f1\u6587\u5355\u8bcd fst \u70ed\u8bcd\u6548\u679c\u3001\u652f\u6301\u81ea\u52a8\u5316\u914d\u7f6e\u7ebf\u7a0b\u53c2\u6570\uff0c\u540c\u65f6\u4fee\u590d\u5df2\u77e5\u7684 crash \u95ee\u9898\u53ca\u5185\u5b58\u6cc4\u6f0f\u95ee\u9898 funasr-runtime-sdk-cpu-0.4.0 c4483ee08f04 2023.11.08 \u652f\u6301\u6807\u70b9\u5927\u6a21\u578b\u3001\u652f\u6301 Ngram \u6a21\u578b\u3001\u652f\u6301 fst \u70ed\u8bcd\u3001\u652f\u6301\u670d\u52a1\u7aef\u52a0\u8f7d\u70ed\u8bcd\u3001runtime \u7ed3\u6784\u53d8\u5316\u9002\u914d funasr-runtime-sdk-cpu-0.3.0 caa64bddbb43 2023.09.19 \u652f\u6301 ITN \u6a21\u578b funasr-runtime-sdk-cpu-0.2.2 2c5286be13e9 2023.08.22 \u96c6\u6210 ffmpeg \u652f\u6301\u591a\u79cd\u97f3\u89c6\u9891\u8f93\u5165\u3001\u652f\u6301\u70ed\u8bcd\u6a21\u578b\u3001\u652f\u6301\u65f6\u95f4\u6233\u6a21\u578b funasr-runtime-sdk-cpu-0.2.0 1ad3d19e0707 2023.07.03 1.0 \u53d1\u5e03 funasr-runtime-sdk-cpu-0.1.0 1ad3d19e0707"},{"location":"sdk_offline_transcription/#2","title":"2. \u670d\u52a1\u5668\u914d\u7f6e","text":"<p>\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u4e1a\u52a1\u9700\u6c42\uff0c\u9009\u62e9\u5408\u9002\u7684\u670d\u52a1\u5668\u914d\u7f6e\uff08\u63a8\u8350\u914d\u7f6e\u4e3a x86 \u8ba1\u7b97\u578b\uff09\uff1a</p> CPU \u5185\u5b58 \u5e76\u53d1 4\u6838vCPU 8G 32 \u8def\u5e76\u53d1 16\u6838vCPU 16G 64 \u8def\u5e76\u53d1 64\u6838vCPU 128G 200 \u8def\u5e76\u53d1"},{"location":"sdk_offline_transcription/#21-cpu","title":"2.1 CPU \u57fa\u51c6\u6027\u80fd\u6d4b\u8bd5","text":"<p>FunASR \u5b98\u65b9\u4ed3\u5e93\u4e0a\u516c\u5e03\u4e00\u7ec4\u4e0d\u540c CPU \u4f7f\u7528 ONNX-CPP \u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c<sup>1</sup>\u3002</p> <pre><code>./funasr-onnx-offline-rtf \\\n    --model-dir ./damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch \\\n    --quantize true \\  # (1)!\n    --wav-path ./aishell1_test.scp  \\\n    --thread-num 32\n</code></pre> <ol> <li><code>--quantize false</code> \u8868\u793a\u91c7\u7528 FP32\uff0c\u5426\u5219\u4f7f\u7528 INT8.</li> </ol>"},{"location":"sdk_offline_transcription/#3","title":"3. \u542f\u52a8\u670d\u52a1","text":""},{"location":"sdk_offline_transcription/#31","title":"3.1 \u542f\u52a8\u955c\u50cf","text":"<pre><code>sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5\nmkdir -p ./funasr-runtime-resources/models\n\nsudo docker run -p 10095:10095 -it --privileged=true \\\n  -v $PWD/funasr-runtime-resources/models:/workspace/models \\\n  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5\n</code></pre>"},{"location":"sdk_offline_transcription/#32","title":"3.2 \u542f\u52a8\u670d\u52a1\u7aef","text":"<pre><code>cd FunASR/runtime\nnohup bash run_server.sh \\\n  --download-model-dir /workspace/models \\\n  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \\\n  --model-dir damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx  \\\n  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \\\n  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \\\n  --itn-dir thuduj12/fst_itn_zh \\\n  --hotword /workspace/models/hotwords.txt &gt; log.txt 2&gt;&amp;1 &amp;\n\n# \u5982\u679c\u60a8\u60f3\u5173\u95edssl\uff0c\u589e\u52a0\u53c2\u6570\uff1a--certfile 0\n# \u5982\u679c\u60a8\u60f3\u4f7f\u7528\u65f6\u95f4\u6233\u6216\u8005nn\u70ed\u8bcd\u6a21\u578b\u8fdb\u884c\u90e8\u7f72\uff0c\u8bf7\u8bbe\u7f6e--model-dir\u4e3a\u5bf9\u5e94\u6a21\u578b\uff1a\n#   damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx\uff08\u65f6\u95f4\u6233\uff09\n#   damo/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404-onnx\uff08nn\u70ed\u8bcd\uff09\n# \u5982\u679c\u60a8\u60f3\u5728\u670d\u52a1\u7aef\u52a0\u8f7d\u70ed\u8bcd\uff0c\u8bf7\u5728\u5bbf\u4e3b\u673a\u6587\u4ef6./funasr-runtime-resources/models/hotwords.txt\u914d\u7f6e\u70ed\u8bcd\uff08docker\u6620\u5c04\u5730\u5740\u4e3a/workspace/models/hotwords.txt\uff09:\n#   \u6bcf\u884c\u4e00\u4e2a\u70ed\u8bcd\uff0c\u683c\u5f0f(\u70ed\u8bcd \u6743\u91cd)\uff1a\u963f\u91cc\u5df4\u5df4 20\uff08\u6ce8\uff1a\u70ed\u8bcd\u7406\u8bba\u4e0a\u65e0\u9650\u5236\uff0c\u4f46\u4e3a\u4e86\u517c\u987e\u6027\u80fd\u548c\u6548\u679c\uff0c\u5efa\u8bae\u70ed\u8bcd\u957f\u5ea6\u4e0d\u8d85\u8fc710\uff0c\u4e2a\u6570\u4e0d\u8d85\u8fc71k\uff0c\u6743\u91cd1~100\uff09\n</code></pre> <ol> <li> <p>CPU Benchmark (ONNX-cpp): https://github.com/modelscope/FunASR/blob/main/runtime/docs/benchmark_onnx_cpp.md \u21a9</p> </li> </ol>"},{"location":"train/","title":"\u8bad\u7ec3","text":""},{"location":"train/#1","title":"1. \u51c6\u5907\u6570\u636e","text":"<p>\u8bad\u7ec3\u6240\u9700\u7684\u6570\u636e\u6587\u4ef6\u662f jsonl \u683c\u5f0f\uff08\u4e00\u884c\u662f\u4e00\u6761 json \u6570\u636e\uff09\uff0c\u901a\u5e38\u6211\u4eec\u4f1a\u5148\u51c6\u5907\u597d .txt \u548c .scp \u6587\u4ef6\uff0c\u7136\u540e\u4f7f\u7528 <code>scp2jsonl</code> \u5de5\u5177\u6765\u751f\u6210\u5bf9\u5e94 jsonl \u6587\u4ef6\u3002</p> \u8bad\u7ec3\u6570\u636e\u6587\u4ef6 train_text.txttrain_wav.scptrain.jsonl \u793a\u4f8b <p>\u5b9e\u9645\u4e0a\u5c31\u4e24\u5217\uff0c\u5de6\u5217\u4e3a\u6570\u636e\u552f\u4e00ID\uff0c\u9700\u4e0e train_wav.scp \u4e2d\u7684 ID \u4e00\u4e00\u5bf9\u5e94\uff0c\u53f3\u5217\u4e3a\u97f3\u9891\u6587\u4ef6\u6807\u6ce8\u6587\u672c\u3002</p> <pre><code>ID0012W0013 \u5f53\u5ba2\u6237\u98ce\u9669\u627f\u53d7\u80fd\u529b\u8bc4\u4f30\u4f9d\u636e\u53d1\u751f\u53d8\u5316\u65f6\nID0012W0014 \u6240\u6709\u53ea\u8981\u5904\u7406 data \u4e0d\u7ba1\u4f60\u662f\u505a machine learning \u505a deep learning\nID0012W0015 he tried to think how it could be\n</code></pre> <p>\u4e5f\u662f\u4e24\u5217\uff0c\u5de6\u5217\u4e3a\u6570\u636e\u552f\u4e00ID\uff0c\u9700\u4e0e train_text.txt \u4e2d\u7684 ID \u4e00\u4e00\u5bf9\u5e94\uff0c\u53f3\u8fb9\u4e3a\u97f3\u9891\u6587\u4ef6\u7684\u8def\u5f84\u3002</p> <pre><code>BAC009S0764W0121 https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/BAC009S0764W0121.wav\nBAC009S0916W0489 https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/BAC009S0916W0489.wav\nID0012W0015 https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_cn_en.wav\n</code></pre> <pre><code>{\"key\": \"ID0012W0013\", \"source\": \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav\", \"source_len\": 88, \"target\": \"\u6b22\u8fce\u5927\u5bb6\u6765\u4f53\u9a8c\u8fbe\u6469\u9662\u63a8\u51fa\u7684\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\", \"target_len\": 19}\n{\"key\": \"ID0012W0014\", \"source\": \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav\", \"source_len\": 88, \"target\": \"he tried to think how it could be\", \"target_len\": 8}\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4f7f\u7528 <code>scp2jsonl</code> \u547d\u4ee4\u6765\u751f\u6210\u8bad\u7ec3\u6570\u636e\u6587\u4ef6\u3002</p> <pre><code>scp2jsonl \\\n    ++scp_file_list='[\"../../../data/list/train_wav.scp\", \"../../../data/list/train_text.txt\"]' \\\n    ++data_type_list='[\"source\", \"target\"]' \\\n    ++jsonl_file_out=\"../../../data/list/train.jsonl\"\n</code></pre> <p>\u5c06 jsonl \u6587\u4ef6\u89e3\u6790\u6210 .txt \u548c .scp \u6587\u4ef6</p> <p><code>jsonl2scp</code> \u547d\u4ee4\u662f <code>scp2jsonl</code> \u7684\u9006\u547d\u4ee4\uff0c\u7528\u4e8e\u5c06 jsonl \u6587\u4ef6\u89e3\u6790\u6210 .txt \u548c .scp \u6587\u4ef6\u3002</p> <pre><code>jsonl2scp \\\n    ++scp_file_list='[\"../../../data/list/train_wav.scp\", \"../../../data/list/train_text.txt\"]' \\\n    ++data_type_list='[\"source\", \"target\"]' \\\n    ++jsonl_file_in=\"../../../data/list/train.jsonl\"\n</code></pre>"},{"location":"train/#2","title":"2. \u6a21\u578b\u8bad\u7ec3","text":""},{"location":"train/#21","title":"2.1 \u547d\u4ee4\u884c\u5feb\u901f\u8bad\u7ec3","text":"<p>FunASR \u63d0\u4f9b\u4e86\u547d\u4ee4\u884c\u5de5\u5177\u53ef\u4ee5\u5feb\u901f\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u79cd\u65b9\u5f0f\u4ec5\u7528\u4e8e\u5feb\u901f\u6d4b\u8bd5\uff0c\u4e0d\u63a8\u8350\u751f\u4ea7\u4f7f\u7528\u3002</p> <pre><code>funasr-train ++model=paraformer-zh \\\n    ++train_data_set_list=data/list/train.jsonl \\\n    ++valid_data_set_list=data/list/val.jsonl \n    ++output_dir=\"./outputs\" &amp;&gt; log.txt &amp;\n</code></pre>"},{"location":"train/#22","title":"2.2 \u811a\u672c\u8bad\u7ec3","text":"<p>\u5b98\u65b9\u4ed3\u5e93\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8bad\u7ec3\u811a\u672c\uff0c\u901a\u8fc7\u6267\u884c <code>bash finetune.sh</code> \u6765\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002</p> <pre><code>funasr/bin/train.py \\\n    ++model=\"${model_name_or_model_dir}\" \\\n    ++train_data_set_list=\"${train_data}\" \\\n    ++valid_data_set_list=\"${val_data}\" \\\n    ++dataset_conf.batch_size=20000 \\\n    ++dataset_conf.batch_type=\"token\" \\\n    ++dataset_conf.num_workers=4 \\\n    ++train_conf.max_epoch=50 \\\n    ++train_conf.log_interval=1 \\\n    ++train_conf.resume=false \\\n    ++train_conf.validate_interval=2000 \\\n    ++train_conf.save_checkpoint_interval=2000 \\\n    ++train_conf.keep_nbest_models=20 \\\n    ++train_conf.avg_nbest_model=10 \\\n    ++optim_conf.lr=0.0002 \\\n    ++output_dir=\"${output_dir}\" &amp;&gt; ${log_file}\n</code></pre> <p>\u8fd9\u91cc\u5bf9\u4f7f\u7528\u53c2\u6570\u8fdb\u884c\u4e00\u4e2a\u7b80\u8981\u8bf4\u660e\u3002</p> \u53c2\u6570 \u8bf4\u660e model \u6a21\u578b\u540d\u79f0 train_data_set_list \u8bad\u7ec3\u6570\u636e\u6587\u4ef6\u8def\u5f84\uff0cjsonl \u683c\u5f0f valid_data_set_list \u9a8c\u8bc1\u6570\u636e\u6587\u4ef6\u8def\u5f84\uff0cjsonl \u683c\u5f0f dataset_conf.batch_type \u9ed8\u8ba4\u662f <code>example</code>\uff0c<code>length</code> \u6216\u8005 <code>token</code> \u8868\u793a\u52a8\u6001\u7ec4 batch\u3002 <code>example</code> \u8868\u793a\u6bcf\u4e2a batch \u4e2d\u56fa\u5b9a <code>batch_size</code> \u4e2a\u6837\u672c\uff1b <code>length</code> \u8868\u793a\u6bcf\u4e2a batch \u56fa\u5b9a\u6837\u672c\u957f\u5ea6\uff0c\u5355\u4f4d\u4e3a fbank \u5e27\u6570\uff081 \u5e27 10ms\uff09\uff1b <code>token</code> \u6807\u5fd7\u6bcf\u4e2a batch \u4e2d token \u4e2a\u6570\u6570\u4f5c\u4e3a <code>batch_size</code>\u3002 dataset_conf.batch_size \u4e0e <code>batch_type</code> \u642d\u914d\u4f7f\u7528 train_conf.max_epoch \u8bad\u7ec3\u5468\u671f\u6570 train_conf.log_interval \u6253\u5370\u65e5\u5fd7\u95f4\u9694\u7684 Step \u6570 train_conf.resume \u9ed8\u8ba4\u4e3a <code>True</code>\uff0c\u662f\u5426\u5f00\u542f\u65ad\u70b9\u91cd\u65b0\u8bad\u7ec3 train_conf.validate_interval \u9ed8\u8ba4\u4e3a 5000\uff0c\u8bad\u7ec3\u4e2d\u505a\u9a8c\u8bc1\u6d4b\u8bd5\u7684\u95f4\u9694 Step \u6570 train_conf.save_checkpoint_interval \u9ed8\u8ba4\u4e3a 5000\uff0c\u8bad\u7ec3\u4e2d\u6bcf\u9694 Step \u6570\u4fdd\u5b58\u4e00\u7248\u6a21\u578b train_conf.avg_keep_nbest_models_type \u9ed8\u8ba4\u4e3a <code>acc</code>\uff0c\u4fdd\u7559 nbest \u7684\u6807\u51c6\u4e3a Acc\uff08\u8d8a\u5927\u8d8a\u597d\uff09\uff1b<code>loss</code> \u8868\u793a\u4fdd\u7559 nbest \u7684\u6807\u51c6\u4e3a Loss\uff08\u8d8a\u5c0f\u8d8a\u597d\uff09\u3002 train_conf.keep_nbest_models \u9ed8\u8ba4\u4e3a 500\uff0c\u4fdd\u7559\u6700\u5927\u591a\u5c11\u4e2a\u6a21\u578b\u53c2\u6570\uff0c\u914d\u5408 <code>avg_keep_nbest_models_type</code> \u6309\u7167\u9a8c\u8bc1\u96c6 acc/loss \u4fdd\u7559\u6700\u4f73\u7684 n \u4e2a\u6a21\u578b\uff0c\u5176\u4ed6\u5220\u9664\uff0c\u8282\u7ea6\u5b58\u50a8\u7a7a\u95f4\u3002 train_conf.avg_nbest_model \u9ed8\u8ba4\u4e3a 10\uff0c\u4fdd\u7559\u6700\u5927\u591a\u5c11\u4e2a\u6a21\u578b\u53c2\u6570\uff0c\u914d\u5408 <code>avg_keep_nbest_models_type</code> \u6309\u7167\u9a8c\u8bc1\u96c6 acc/loss \u5bf9\u6700\u4f73\u7684 n \u4e2a\u6a21\u578b\u5e73\u5747\u3002 train_conf.accum_grad \u9ed8\u8ba4\u4e3a 1\uff0c\u5f00\u542f\u68af\u5ea6\u7d2f\u8ba1\u529f\u80fd train_conf.grad_clip \u9ed8\u8ba4\u4e3a 10\uff0c\u5f00\u542f\u68af\u5ea6\u622a\u65ad\u529f\u80fd train_conf.use_fp16 \u9ed8\u8ba4\u4e3a <code>False</code>\uff0c\u5f00\u542f FP16 \u8bad\u7ec3\uff0c\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\u3002 optim_conf.lr \u5b66\u4e60\u7387 output_dir \u6a21\u578b\u4fdd\u5b58\u8def\u5f84"},{"location":"train/#23-gpu","title":"2.3 \u591aGPU\u8bad\u7ec3","text":""},{"location":"train/#gpu","title":"\u5355\u673a\u591aGPU","text":"<pre><code>export CUDA_VISIBLE_DEVICES=\"0,1\"\ngpu_num=$(echo $CUDA_VISIBLE_DEVICES | awk -F \",\" '{print NF}')\n\ntorchrun --nnodes 1 --nproc_per_node ${gpu_num} \\\n    ../../../funasr/bin/train.py ${train_args}\n</code></pre> <p>\u5176\u4e2d\uff0c<code>--nnodes</code> \u8868\u793a\u53c2\u4e0e\u7684\u8282\u70b9\u603b\u6570\uff0c<code>--nproc_per_node</code> \u8868\u793a\u6bcf\u4e2a\u8282\u70b9\u4e0a\u8fd0\u884c\u7684\u8fdb\u7a0b\u6570\u3002</p>"},{"location":"train/#gpu_1","title":"\u591a\u673a\u591aGPU","text":"<p>\u5728\u4e3b\u8282\u70b9\u4e0a\uff0c\u5047\u8bbe IP \u4e3a 192.168.1.1\uff0c\u7aef\u53e3\u4e3a 12345\uff0c\u4f7f\u7528\u7684\u662f 2 \u4e2a GPU\uff0c\u5219\u8fd0\u884c\u5982\u4e0b\u547d\u4ee4\uff1a</p> <pre><code>export CUDA_VISIBLE_DEVICES=\"0,1\"\ngpu_num=$(echo $CUDA_VISIBLE_DEVICES | awk -F \",\" '{print NF}')\n\ntorchrun --nnodes 2 --node_rank 0 --nproc_per_node ${gpu_num} \\\n    --master_addr 192.168.1.1 --master_port 12345 \\\n    ../../../funasr/bin/train.py ${train_args}\n</code></pre> <p>\u5728\u4ece\u8282\u70b9\u4e0a\uff08\u5047\u8bbe IP \u4e3a 192.168.1.2\uff09\uff0c\u4f60\u9700\u8981\u786e\u4fdd <code>MASTER_ADDR</code> \u548c <code>MASTER_PORT</code> \u73af\u5883\u53d8\u91cf\u4e0e\u4e3b\u8282\u70b9\u8bbe\u7f6e\u7684\u4e00\u81f4\uff0c\u5e76\u8fd0\u884c\u540c\u6837\u7684\u547d\u4ee4\uff1a</p> <pre><code>export CUDA_VISIBLE_DEVICES=\"0,1\"\ngpu_num=$(echo $CUDA_VISIBLE_DEVICES | awk -F \",\" '{print NF}')\n\ntorchrun --nnodes 2 --node_rank 1 --nproc_per_node ${gpu_num} \\\n    --master_addr 192.168.1.1 --master_port 12345 \\\n    ../../../funasr/bin/train.py ${train_args}\n</code></pre> <p>\u5176\u4e2d\uff0c<code>--nnodes</code> \u8868\u793a\u53c2\u4e0e\u7684\u8282\u70b9\u603b\u6570\uff0c<code>--node_rank</code> \u8868\u793a\u5f53\u524d\u8282\u70b9 id\uff0c<code>--nproc_per_node</code> \u8868\u793a\u6bcf\u4e2a\u8282\u70b9\u4e0a\u8fd0\u884c\u7684\u8fdb\u7a0b\u6570\uff08\u901a\u5e38\u4e3a gpu \u4e2a\u6570\uff09\u3002</p>"},{"location":"train/#24","title":"2.4 \u8bad\u7ec3\u65e5\u5fd7","text":"log.txt<pre><code>[2024-03-21 15:55:52,137][root][INFO] - train, rank: 3, epoch: 0/50, step: 6990/1, total step: 6990, (loss_avg_rank: 0.327), (loss_avg_epoch: 0.409), (ppl_avg_epoch: 1.506), (acc_avg_epoch: 0.795), (lr: 1.165e-04), [('loss_att', 0.259), ('acc', 0.825), ('loss_pre', 0.04), ('loss', 0.299), ('batch_size', 40)], {'data_load': '0.000', 'forward_time': '0.315', 'backward_time': '0.555', 'optim_time': '0.076', 'total_time': '0.947'}, GPU, memory: usage: 3.830 GB, peak: 18.357 GB, cache: 20.910 GB, cache_peak: 20.910 GB\n[2024-03-21 15:55:52,139][root][INFO] - train, rank: 1, epoch: 0/50, step: 6990/1, total step: 6990, (loss_avg_rank: 0.334), (loss_avg_epoch: 0.409), (ppl_avg_epoch: 1.506), (acc_avg_epoch: 0.795), (lr: 1.165e-04), [('loss_att', 0.285), ('acc', 0.823), ('loss_pre', 0.046), ('loss', 0.331), ('batch_size', 36)], {'data_load': '0.000', 'forward_time': '0.334', 'backward_time': '0.536', 'optim_time': '0.077', 'total_time': '0.948'}, GPU, memory: usage: 3.943 GB, peak: 18.291 GB, cache: 19.619 GB, cache_peak: 19.619 GB\n</code></pre> <p>\u901a\u8fc7\u65e5\u5fd7\u6587\u4ef6\u53ef\u4ee5\u76f4\u63a5\u67e5\u770b\u8bad\u7ec3\u4fe1\u606f\uff0c\u8fd9\u91cc\u5bf9\u4e00\u4e9b\u6307\u6807\u8fdb\u884c\u4e0b\u8bf4\u660e:</p> <ul> <li>rank \u8868\u793a GPU ID\u3002</li> <li>loss_avg_rank \u8868\u793a\u5f53\u524d Step \u6240\u6709 GPU \u5e73\u5747\u635f\u5931\u503c\u3002</li> <li>loss/ppl/acc_avg_epoch \u8868\u793a\u5f53\u524d Epoch \u622a\u6b62\u5f53\u524d Step \u6570\u65f6\uff0c\u603b\u5e73\u5747 Loss/PPL/Acc\u3002\u6b64\u5916\uff0cEpoch \u7ed3\u675f\u65f6\u7684\u6700\u540e\u4e00\u4e2a Step \u8868\u793a\u603b\u5e73\u5747 Loss/PPL/Acc\uff0c\u63a8\u8350\u4f7f\u7528 Acc \u6307\u6807\u3002</li> <li>lr \u8868\u793a\u5f53\u524d Step \u7684\u5b66\u4e60\u7387\u3002</li> <li><code>[('loss_att', 0.259), ('acc', 0.825), ('loss_pre', 0.04), ('loss', 0.299), ('batch_size', 40)]</code> \u8868\u793a\u5f53\u524d GPU ID \u7684\u5177\u4f53\u6570\u636e\u3002</li> <li>total_time \u8868\u793a\u5355\u4e2a Step \u603b\u8017\u65f6\u3002</li> <li><code>GPU, memory</code> \u5206\u522b\u8868\u793a\u201c\u6a21\u578b\u4f7f\u7528/\u5cf0\u503c\u663e\u5b58\u201d \u4ee5\u53ca \u201c\u6a21\u578b+\u7f13\u5b58\u4f7f\u7528/\u5cf0\u503c\u663e\u5b58\u201d\u3002</li> </ul> <p>\u4f60\u719f\u6089 TensorBoard \u53ef\u89c6\u5316\u5de5\u5177\u7684\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u5bf9\u65e5\u5fd7\u6587\u4ef6\u8fdb\u884c\u66f4\u76f4\u89c2\u7684\u8ba4\u8bc6\u3002\u5f00\u542f\u670d\u52a1\u540e\uff0c\u5728\u6d4f\u89c8\u5668\u4e2d\u8bbf\u95ee http://localhost:6006 \u67e5\u770b\u65e5\u5fd7\u4fe1\u606f\u3002</p> <pre><code>tensorboard --logdir /xxxx/FunASR/examples/industrial_data_pretraining/paraformer/outputs/log/tensorboard\n</code></pre>"},{"location":"train/#3","title":"3. \u6a21\u578b\u6d4b\u8bd5","text":""},{"location":"train/#31-configurationjson","title":"3.1 \u6709 configuration.json","text":"<p>\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u6587\u4ef6\u5939 <code>ft_model</code> \u4e2d\u5b58\u5728 configuration.json \u6587\u4ef6\uff0c\u53ea\u9700\u8981\u5c06\u4e4b\u524d ModelScope \u6216 HuggingFace \u4e0a\u6a21\u578b\u540d\u79f0\u66f4\u6539\u4e3a <code>ft_model</code> \u5373\u53ef\uff0c\u4f7f\u7528\u4e0a\u5e76\u65e0\u592a\u5927\u5dee\u5f02\u3002</p> \u4f7f\u7528\u8bad\u7ec3\u540e\u7684\u6a21\u578b \u547d\u4ee4\u884c\u8c03\u7528Python \u8c03\u7528 <pre><code>python -m funasr.bin.inference ++model=\"./model_dir\" \\\n    ++input==\"${input}\" \\\n    ++output_dir=\"${output_dir}\"\n</code></pre> <pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"./model_dir\")\nres = model.generate(input=wav_file)\nprint(res)\n</code></pre>"},{"location":"train/#32-configurationjson","title":"3.2 \u65e0 configuration.json","text":"<p>\u5982\u679c\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u6587\u4ef6\u5939 <code>ft_model</code> \u4e2d\u4e0d\u5b58\u5728 configuration.json \u6587\u4ef6\uff0c\u90a3\u4e48\u9700\u8981\u624b\u52a8\u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\u3002</p> <pre><code>python -m funasr.bin.inference \\\n    --config-path \"${local_path}\" \\\n    --config-name \"${config}\" \\\n    ++init_param=\"${init_param}\" \\\n    ++tokenizer_conf.token_list=\"${tokens}\" \\\n    ++frontend_conf.cmvn_file=\"${cmvn_file}\" \\\n    ++input=\"${input}\" \\\n    ++output_dir=\"${output_dir}\" \\\n    ++device=\"${device}\"\n</code></pre> <p>\u8fd9\u91cc\u5bf9\u4e0a\u9762\u53c2\u6570\u505a\u4e00\u4e2a\u7b80\u8981\u4ecb\u7ecd\u3002</p> \u53c2\u6570 \u8bf4\u660e config-path \u8bad\u7ec3\u4e2d\u7684 config.yaml \u6587\u4ef6 config-name \u914d\u7f6e\u6587\u4ef6\u540d\uff0c\u4e00\u822c\u4e3a config.yaml\uff0c\u652f\u6301 YAML \u548c JSON \u683c\u5f0f init_param \u9700\u8981\u6d4b\u8bd5\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e00\u822c\u4e3a model.pt tokenizer_conf.token_list \u8bcd\u8868\u6587\u4ef6\u8def\u5f84\uff0c\u4e00\u822c\u5728 config.yaml \u6709\u6307\u5b9a\uff0c\u65e0\u9700\u518d\u624b\u52a8\u6307\u5b9a\uff0c\u5f53 config.yaml \u4e2d\u8def\u5f84\u4e0d\u6b63\u786e\u65f6\uff0c\u9700\u8981\u5728\u6b64\u5904\u624b\u52a8\u6307\u5b9a\u3002 frontend_conf.cmvn_file wav \u63d0\u53d6 fbank \u4e2d\u7528\u5230\u7684 cmvn \u6587\u4ef6\uff0c\u4e00\u822c\u5728 config.yaml \u6709\u6307\u5b9a\uff0c\u65e0\u9700\u518d\u624b\u52a8\u6307\u5b9a\uff0c\u5f53 config.yaml \u4e2d\u8def\u5f84\u4e0d\u6b63\u786e\u65f6\uff0c\u9700\u8981\u5728\u6b64\u5904\u624b\u52a8\u6307\u5b9a\u3002"},{"location":"vad/","title":"\u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b","text":"<p>\u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b\u901a\u5e38\u79f0\u4e3a VAD\uff0c\u7528\u4e8e\u68c0\u6d4b\u6709\u58f0\u97f3\u9891\u7247\u6bb5\u3002FunASR \u4e2d\u901a\u8fc7 fsmn-vad \u6a21\u578b\u8fdb\u884c\u8c03\u7528\uff0c\u652f\u6301\u5b9e\u65f6\u548c\u975e\u5b9e\u65f6\u3002</p>"},{"location":"vad/#1-vad","title":"1. \u975e\u5b9e\u65f6 VAD","text":"<p>\u975e\u5b9e\u65f6\u7684 VAD \u68c0\u6d4b\u5728 Python \u4e2d\u8c03\u7528\u5f88\u7b80\u5355\uff0c\u5176\u8f93\u51fa\u683c\u5f0f\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e3a\u4e00\u4e2a\u6709\u6548\u97f3\u9891\u7247\u6bb5\uff0c\u5305\u542b\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\uff0c\u5355\u4f4d\u4e3a\u6beb\u79d2\u3002</p> <pre><code>from funasr import AutoModel\n\nmodel = AutoModel(model=\"fsmn-vad\")\nwav_file = f\"{model.model_path}/example/vad_example.wav\"\nres = model.generate(input=wav_file)\nprint(res)\n</code></pre>"},{"location":"vad/#2-vad","title":"2. \u5b9e\u65f6 VAD","text":"<p>FunASR \u4e2d fsmn-vad \u4e5f\u53ef\u4ee5\u8fdb\u884c\u5b9e\u65f6\u8bed\u97f3\u7aef\u70b9\u68c0\u6d4b\uff0c\u4ee5\u4e0b\u793a\u4f8b\u662f\u8bfb\u53d6\u4e00\u4e2a\u97f3\u9891\u6587\u4ef6\uff0c\u7136\u540e\u904d\u5386\u5b57\u8282\u6d41\u6765\u6a21\u62df\u5b9e\u65f6\u8bc6\u522b\u7684\u573a\u666f\u3002</p> <pre><code>import soundfile\nfrom funasr import AutoModel\n\n\nchunk_size = 200  # Unit: ms\nmodel = AutoModel(model=\"fsmn-vad\")\nwav_file = f\"{model.model_path}/example/vad_example.wav\"\nspeech, sample_rate = soundfile.read(wav_file)\nchunk_stride = int(chunk_size * sample_rate / 1000)\n\ncache = {}\ntotal_chunk_num = int(len(speech - 1) / chunk_stride + 1)\nfor i in range(total_chunk_num):\n    speech_chunk = speech[i * chunk_stride: (i + 1) * chunk_stride]\n    is_final = i == total_chunk_num - 1\n    res = model.generate(\n        input=speech_chunk,\n        cache=cache,\n        is_final=is_final,\n        chunk_size=chunk_size\n        )\n\n    if len(res[0][\"value\"]):\n        print(res)\n</code></pre> <p>\u6b64\u5916\uff0c\u6d41\u5f0f VAD \u6a21\u578b\u8f93\u51fa\u683c\u5f0f\u4e3a\u4e0e\u975e\u5b9e\u65f6\u573a\u666f\u4e5f\u7565\u6709\u4e0d\u540c\uff1a</p> <ol> <li>\u540c\u975e\u5b9e\u65f6 VAD \u8f93\u51fa\u7ed3\u679c\uff0c\u5217\u8868\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5305\u542b\u6709\u6548\u7247\u6bb5\u7684\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u3002</li> <li><code>[[beg, -1]]</code> \u8868\u793a\u53ea\u68c0\u6d4b\u5230\u8d77\u59cb\u70b9\u3002</li> <li><code>[[-1, end]]</code> \u8868\u793a\u53ea\u68c0\u6d4b\u5230\u7ed3\u675f\u70b9\u3002</li> <li><code>[]</code> \u8868\u793a\u65e2\u6ca1\u6709\u68c0\u6d4b\u5230\u8d77\u59cb\u70b9\uff0c\u4e5f\u6ca1\u6709\u68c0\u6d4b\u5230\u7ed3\u675f\u70b9\u3002</li> </ol>"},{"location":"blog/","title":"Blog","text":""}]}